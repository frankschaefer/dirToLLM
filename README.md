# FileInventory - OneDrive Dokumenten-Zusammenfassung (macOS)

**Version:** 1.18.0
**Datum:** 2025-12-30
**Lizenz:** Propriet√§r

## √úbersicht

FileInventory ist ein intelligentes Python-Tool zur automatischen Analyse und Zusammenfassung von Dokumenten in OneDrive-Verzeichnissen. Das System nutzt lokale Large Language Models (LLM) √ºber LM Studio, um kompakte, aussagekr√§ftige Zusammenfassungen von verschiedenen Dateiformaten zu erstellen.

### Hauptfunktionen

- **Multiformat-Unterst√ºtzung**: PDF, Word (.docx/.doc), Excel (.xlsx/.xls/.xlsm/.xltx), PowerPoint (.pptx/.ppt), Text, Markdown und Bilder
- **OCR-Unterst√ºtzung**: Automatische Texterkennung f√ºr gescannte PDFs mit Tesseract OCR
- **RAG-Optimierung**: Wissensextraktion f√ºr semantische Suche mit Schl√ºsselbegriffen und strukturierter Zusammenfassung
- **Named Entity Recognition**: Automatische Extraktion von Firmen, Personen, Institutionen und Organisationen
- **DSGVO-Klassifizierung**: Automatische Erkennung besonders schutzbed√ºrftiger personenbezogener Daten gem√§√ü Art. 9 DSGVO und ¬ß 26 BDSG (NEU in v1.18.0)
- **Kombinierte Datenbank**: Erstellt durchsuchbare JSON-Datenbanken f√ºr ChatGPT/Claude
- **macOS-optimiert**: Native macOS-Unterst√ºtzung mit OneDrive-Integration
- **LLM-basierte Analyse**: Intelligente Zusammenfassungen mit RAG-optimierten, dateityp-spezifischen Prompts
- **Vision-F√§higkeit**: Bildanalyse und -beschreibung mittels multimodaler Modelle
- **Icon-Filter**: Automatisches √úberspringen kleiner Bilder (<10 KB)
- **Validierung**: Automatische √úberpr√ºfung und Neuerstellung fehlerhafter JSON-Ausgaben
- **Fortschritts√ºberwachung**: Detaillierte Zeitsch√§tzungen und Statistiken mit Dateiendungs-√úbersicht und OCR-Z√§hler
- **Interaktive Steuerung**: Pause/Resume-Funktionalit√§t w√§hrend der Verarbeitung
- **Professionelle Fehlerbehandlung**: Intelligente LM Studio-Fehlerbehandlung mit Benutzerabfragen
- **Legacy-Format-Support**: Unterst√ºtzung f√ºr alte Office-Formate (.doc, .ppt, .xls)

---

## Systemanforderungen

### Betriebssystem
- **macOS**: Version 10.15 (Catalina) oder h√∂her
- Getestet auf macOS 26.2

### Software
- **Python**: Version 3.8 oder h√∂her (Python 3.12+ empfohlen)
- **LM Studio**: Aktuelle Version mit laufendem lokalem Server
- **OneDrive**: OneDrive App f√ºr macOS installiert und synchronisiert

### Hardware-Empfehlungen
- **RAM**: Mindestens 8 GB (16 GB empfohlen)
- **GPU**: Optional, beschleunigt LLM-Inferenz erheblich (Apple Silicon bevorzugt)
- **Festplatte**: Ausreichend Speicherplatz f√ºr JSON-Ausgaben

---

## Installation

### 1. Python Installation auf macOS

#### Option A: Homebrew (Empfohlen)
```bash
# Installieren Sie Homebrew falls noch nicht vorhanden
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installieren Sie Python
brew install python@3.12
```

#### Option B: Python.org
1. Besuchen Sie [python.org/downloads](https://www.python.org/downloads/)
2. Laden Sie Python 3.12.x f√ºr macOS herunter
3. Installieren Sie das .pkg-Paket

#### Verifizierung
```bash
python3 --version
# Erwartete Ausgabe: Python 3.12.x
```

### 2. Python-Bibliotheken installieren

√ñffnen Sie Terminal und f√ºhren Sie folgende Befehle aus:

```bash
# Navigieren Sie zum Skript-Verzeichnis
cd ~/Library/CloudStorage/Dropbox/Frank/Code/MKU

# Optional: Erstellen Sie eine virtuelle Umgebung
python3 -m venv .venv
source .venv/bin/activate

# Installieren Sie alle erforderlichen Bibliotheken
pip install -r requirements.txt
```

#### Einzelne Bibliotheken (zur Referenz)

| Bibliothek | Zweck | Version |
|------------|-------|---------|
| `pdfplumber` | PDF-Textextraktion | 0.11.4 |
| `python-docx` | Word-Dokumentenverarbeitung | 1.1.2 |
| `python-pptx` | PowerPoint-Analyse | 1.0.2 |
| `openpyxl` | Excel-Datenextraktion | 3.1.5 |
| `requests` | HTTP-Kommunikation mit LM Studio | 2.32.3 |
| `pytesseract` | OCR f√ºr gescannte PDFs | 0.3.13 |
| `Pillow` | Bildverarbeitung f√ºr OCR | 12.0.0 |

### 3. LM Studio Installation und Konfiguration

#### Installation
1. Laden Sie LM Studio f√ºr macOS herunter: [lmstudio.ai](https://lmstudio.ai/)
2. Installieren Sie die Anwendung
3. Laden Sie ein LLM-Modell herunter (Empfehlungen siehe unten)

#### Modell-Empfehlungen

##### F√ºr Textverarbeitung (Standard)
- **mistralai/ministral-3-14b-reasoning** (empfohlen, getestet - 262k Tokens Context, hohe Pr√§zision)
- **ministral-3-3b-instruct** (leichtgewichtig, schnell)
- **Mistral-7B-Instruct** (ausgewogen)
- **Llama-3-8B-Instruct** (hochwertig)
- **Qwen-2.5-14B** (sehr gut f√ºr deutsche Texte, 32k Tokens Context)

##### F√ºr Bildverarbeitung (Vision-Modelle)
- **LLaVA-v1.6-Mistral-7B**
- **BakLLaVA-1**
- **Obsidian-3B-Multimodal**

#### Server-Konfiguration
1. √ñffnen Sie LM Studio
2. Laden Sie das gew√ºnschte Modell
3. Wechseln Sie zur "Local Server" Ansicht
4. Starten Sie den Server auf Port **1234** (Standard)
5. Notieren Sie den "Model Name" (wird in `FileInventory.py` ben√∂tigt)

#### Konfiguration im Skript
√ñffnen Sie `FileInventory.py` und passen Sie bei Bedarf an:

```python
LMSTUDIO_API_URL = "http://localhost:1234/v1/chat/completions"
MODEL_NAME = "local-model"  # Ersetzen Sie mit dem Namen aus LM Studio

# Modell Context-L√§nge (maximale Anzahl Tokens)
# Passen Sie dies an Ihr Modell an:
# - Kleinere Modelle (z.B. Llama 3 8B): 8192
# - Gr√∂√üere Modelle (z.B. Qwen 2.5 14B): 32768
# - Reasoning-Modelle (z.B. mistralai/ministral-3-14b-reasoning): 262144
MAX_CONTEXT_TOKENS = 262144
```

### 4. Tesseract OCR Installation (f√ºr gescannte PDFs)

#### Installation auf macOS

```bash
# Installation via Homebrew (empfohlen)
brew install tesseract

# Deutsche Sprachdaten installieren
brew install tesseract-lang
```

#### Alternative Installation

```bash
# Oder nur deutsche Sprachdaten
brew install tesseract
# Die deutschen Sprachdaten werden automatisch mitinstalliert
```

#### Verifizierung

```bash
tesseract --version
# Erwartete Ausgabe: tesseract 5.x.x

# Pr√ºfe verf√ºgbare Sprachen
tesseract --list-langs
# Sollte 'deu' (Deutsch) enthalten
```

#### Hinweise zur OCR-Funktionalit√§t

- **Automatische Erkennung**: Das System erkennt automatisch gescannte PDFs (Seiten mit <10 Zeichen extrahiertem Text)
- **Hohe Aufl√∂sung**: OCR verwendet 300 DPI f√ºr optimale Texterkennung
- **Deutsch-Optimiert**: Verwendet 'deu' Sprachmodell f√ºr deutsche Texte
- **Fortschrittsanzeige**: Bei mehrseitigen gescannten PDFs wird der OCR-Fortschritt angezeigt
- **Statistik**: OCR-verarbeitete Dokumente werden in den Berichten separat gez√§hlt
- **Optional**: Wenn Tesseract nicht installiert ist, werden gescannte PDFs √ºbersprungen (mit Warnung)

---

## Konfiguration

### Verzeichnispfade anpassen

√ñffnen Sie `FileInventory.py` und passen Sie die Pfade an:

```python
# Quellverzeichnis (OneDrive)
SRC_ROOT = os.path.expanduser("~/OneDrive - CompanyName")

# Zielverzeichnis f√ºr JSON-Ausgaben
DST_ROOT = os.path.expanduser("~/LLM")
```

### Dateitypen konfigurieren

Standardm√§√üig werden folgende Formate verarbeitet:

```python
EXTENSIONS = {
    ".pdf",                                    # PDF-Dokumente
    ".docx", ".doc",                          # Word-Dokumente (neu und alt)
    ".pptx", ".ppt",                          # PowerPoint-Pr√§sentationen (neu und alt)
    ".xlsx", ".xls", ".xlsm", ".xltx",       # Excel-Dateien (neu, alt, Makro, Vorlagen)
    ".txt", ".md",                            # Textdateien
    ".png", ".jpg", ".jpeg"                   # Bilddateien
}
```

**Anpassung**: Entfernen oder erg√§nzen Sie Dateitypen nach Bedarf.

### Minimale Bildgr√∂√üe anpassen

```python
# Minimale Dateigr√∂√üe f√ºr Bilddateien (in Bytes) - ignoriere kleine Icons
MIN_IMAGE_SIZE = 10 * 1024  # 10 KB
```

---

## Verwendung

### Kommandozeilenparameter

FileInventory unterst√ºtzt folgende Kommandozeilenparameter:

```bash
# Hilfe anzeigen
python3 FileInventory.py -h
python3 FileInventory.py --help

# Version anzeigen
python3 FileInventory.py --version

# Mit benutzerdefinierten Verzeichnissen
python3 FileInventory.py --src ~/Documents --dst ~/Summaries

# Kleineres Modell mit 8k Token Context
python3 FileInventory.py --max-tokens 8192

# Vollst√§ndig benutzerdefiniert
python3 FileInventory.py --src ~/Docs --dst ~/Summaries --max-tokens 32768

# Kombinierte Datenbank erstellen (empfohlen f√ºr ChatGPT/Claude)
python3 FileInventory.py --create-database

# Datenbank mit benutzerdefinierter Gr√∂√üe
python3 FileInventory.py --create-database --max-database-size 50

# Datenbank in benutzerdefiniertem Verzeichnis
python3 FileInventory.py --create-database --database-output ~/MyDatabase

# DSGVO-Klassifizierung f√ºr bestehende JSONs hinzuf√ºgen
python3 FileInventory.py --update-dsgvo

# Standard-Verzeichnisse und -Einstellungen verwenden
python3 FileInventory.py
```

**Verf√ºgbare Parameter:**

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `-h`, `--help` | Zeigt Hilfe und alle verf√ºgbaren Optionen | - |
| `--version` | Zeigt Versionsinformation | - |
| `--src VERZEICHNIS` | Quellverzeichnis f√ºr Dokumente | `~/OneDrive - CompanyName` |
| `--dst VERZEICHNIS` | Zielverzeichnis f√ºr JSON-Dateien | `~/LLM` |
| `--max-tokens TOKENS` | Maximale Context-L√§nge des Modells in Tokens | `262144` |
| `--create-database` | Erstellt kombinierte JSON-Datenbank aus allen einzelnen JSON-Dateien | - |
| `--database-output DIR` | Ausgabeverzeichnis f√ºr Datenbank-Dateien | `~/LLM/database` |
| `--max-database-size MB` | Maximale Gr√∂√üe pro Datenbank-Datei in MB | `30` |
| `--cleanup-phones` | Bereinigt ung√ºltige Telefonnummern aus allen JSON-Dateien | - |
| `--update-dsgvo` | Aktualisiert alle JSON-Dateien mit DSGVO-Klassifizierung | - |

### Basis-Ausf√ºhrung

```bash
cd ~/Library/CloudStorage/Dropbox/Frank/Code/MKU

# Mit virtueller Umgebung
source .venv/bin/activate
python3 FileInventory.py

# Ohne virtuelle Umgebung
python3 FileInventory.py

# Mit benutzerdefinierten Verzeichnissen
python3 FileInventory.py --src ~/Documents --dst ~/Summaries
```

### Interaktive Steuerung w√§hrend der Ausf√ºhrung

#### Pause/Resume
- **Pause**: Dr√ºcken Sie Enter w√§hrend der Verarbeitung
- **Fortsetzen**: W√§hlen Sie `J` (Ja)
- **Abbrechen**: W√§hlen Sie `N` (Nein)

#### Fehlerbehandlung (NEU in v1.4.0)
Beim ersten LM Studio-Fehler werden Sie gefragt:

```
================================================================================
FEHLER BEI DER VERARBEITUNG
================================================================================

Datei: beispiel.pdf
Fehler: Netzwerkfehler bei der Zusammenfassung: Connection timeout

--------------------------------------------------------------------------------

Wie m√∂chten Sie fortfahren?

  [A] Abbrechen - Verarbeitung sofort beenden
  [W] Weiter ohne Fehlerabfragen - Weitere Fehler stillschweigend √ºberspringen
  [F] Weiter mit Fehlerabfragen - Bei jedem Fehler erneut nachfragen

--------------------------------------------------------------------------------
Bitte w√§hlen Sie (A/W/F):
```

**Optionen:**
- **A**: Programm wird sofort beendet
- **W**: Fehlerhafte Dateien werden √ºbersprungen, keine weiteren Abfragen
- **F**: Bei jedem Fehler erfolgt eine erneute Abfrage

### Kombinierte Datenbank erstellen (NEU in v1.9.0)

Nach der Verarbeitung Ihrer Dokumente k√∂nnen Sie eine kombinierte JSON-Datenbank erstellen, die alle Zusammenfassungen in wenigen gro√üen Dateien zusammenfasst. Dies ist ideal f√ºr die Verwendung mit ChatGPT oder Claude.

#### Datenbank erstellen

```bash
# Aktiviere virtuelle Umgebung
source .venv/bin/activate

# Erstelle Datenbank mit Standard-Einstellungen (max 30 MB pro Datei)
python3 FileInventory.py --create-database
```

#### Ausgabe

Die Datenbank wird standardm√§√üig im Verzeichnis `~/LLM/database/` erstellt:

```
~/LLM/database/
  ‚îú‚îÄ‚îÄ file_database_001.json  (10.19 MB, 6,283 Dokumente)
```

#### Datenbankstruktur

Jede Datenbank-Datei enth√§lt Metadaten und alle Dokumente:

```json
{
  "metadata": {
    "created": "2025-12-28T19:18:03.965074",
    "source_directory": "/Users/username/OneDrive - CompanyName",
    "json_directory": "/Users/username/LLM",
    "script_version": "1.9.0",
    "script_date": "2025-12-28",
    "batch_number": 1,
    "documents_in_batch": 6283,
    "max_size_mb": 30
  },
  "documents": [
    {
      "path": "Projekte/Kunde_A/Beispieldokument.pdf",
      "ext": ".pdf",
      "size": 1048576,
      "summary": "...",
      "keywords": ["Projekt", "Kunde A", "..."]
    },
    ...
  ]
}
```

#### Verwendung mit ChatGPT/Claude

1. **Lade die Datenbank-Datei hoch** zu ChatGPT oder Claude
2. **Stelle Fragen** √ºber Ihre Dokumente:
   - "Suche alle Projekte mit dem Kunden X"
   - "Welche Dokumente erw√§hnen digitale Transformation?"
   - "Finde alle PDFs von [specific person]"
   - "Liste alle Dokumente mit dem Keyword 'Innovation' auf"

#### Erweiterte Optionen

```bash
# Kleinere Dateien (z.B. 5 MB f√ºr bessere Uploads)
python3 FileInventory.py --create-database --max-database-size 5

# Benutzerdefiniertes Ausgabeverzeichnis
python3 FileInventory.py --create-database --database-output ~/Desktop/Datenbank

# Mit benutzerdefinierten Quell-Verzeichnissen
python3 FileInventory.py --dst ~/Summaries --create-database
```

#### Vorteile der Datenbank

- **Schnellere Uploads**: Eine gro√üe Datei statt tausende kleine
- **Bessere Durchsuchbarkeit**: ChatGPT/Claude kann alle Dokumente auf einmal durchsuchen
- **Metadaten**: Enth√§lt Versionsinformationen und Verarbeitungsdetails
- **Flexible Gr√∂√üe**: Automatische Aufteilung bei √úberschreitung der max. Gr√∂√üe

### Ausgabeformat (Einzelne JSON-Dateien)

F√ºr jede verarbeitete Datei wird eine JSON-Datei erstellt:

```json
{
  "path": "Projekte/Kunde_A/Beispieldokument.pdf",
  "ext": ".pdf",
  "size": 1048576,
  "created": "2025-01-15T10:30:00",
  "modified": "2025-01-20T14:45:00",
  "chars": 15420,
  "summary": "Projekt√ºbersicht f√ºr Kunde A mit John Doe als Projektleiter. Beschreibt Meilensteine Q1-Q4 2025 mit Fokus auf digitale Transformation und Prozessoptimierung.",
  "keywords": [
    "Projekt√ºbersicht",
    "John Doe",
    "Meilensteine 2025",
    "Digitale Transformation",
    "Prozessoptimierung",
    "Q1-Q4"
  ],
  "entities": {
    "companies": ["Kunde A GmbH"],
    "persons": ["John Doe"],
    "institutions": [],
    "organizations": [],
    "projects": [],
    "urls": [],
    "emails": ["kontakt@kunde-a.de"],
    "phone_numbers": ["+49 30 12345678"]
  },
  "dsgvo_classification": {
    "contains_sensitive_data": false,
    "data_categories": [],
    "legal_basis": [],
    "protection_level": null,
    "detected_keywords": {}
  },
  "ocr_info": {
    "used_ocr": true,
    "ocr_pages": 15,
    "total_pages": 20,
    "ocr_chars": 12350
  }
}
```

#### Feld√ºbersicht

| Feld | Beschreibung |
|------|--------------|
| `path` | Relativer Pfad zur Quelldatei (inkl. Dateiname) |
| `ext` | Dateierweiterung |
| `size` | Dateigr√∂√üe in Bytes |
| `created` | Erstellungszeitpunkt (ISO 8601) |
| `modified` | Letzte √Ñnderung (ISO 8601) |
| `chars` | Anzahl extrahierter Zeichen |
| `summary` | KI-generierte Zusammenfassung (max. 1500 Zeichen, RAG-optimiert, auf Deutsch) |
| `keywords` | **Array:** Extrahierte Schl√ºsselbegriffe als Liste f√ºr schnelle Kategorisierung |
| `entities` | **Objekt:** Named Entities (Firmen, Personen, Institutionen, Organisationen) |
| `entities.companies` | **Array:** Liste extrahierter Firmennamen |
| `entities.persons` | **Array:** Liste extrahierter Personennamen |
| `entities.institutions` | **Array:** Liste extrahierter Institutionen (Beh√∂rden, Universit√§ten, etc.) |
| `entities.organizations` | **Array:** Liste extrahierter Organisationen (Vereine, Verb√§nde, NGOs, etc.) |
| `entities.projects` | **Array:** Liste extrahierter Projektnamen |
| `entities.urls` | **Array:** Liste extrahierter URLs |
| `entities.emails` | **Array:** Liste extrahierter E-Mail-Adressen |
| `entities.phone_numbers` | **Array:** Liste extrahierter Telefonnummern |
| `dsgvo_classification` | **Objekt:** DSGVO-Klassifizierung (NEU in v1.18.0) |
| `dsgvo_classification.contains_sensitive_data` | Boolean - ob besonders schutzbed√ºrftige Daten erkannt wurden |
| `dsgvo_classification.data_categories` | **Array:** Erkannte Kategorien (z.B. GEHALTSABRECHNUNG, LEBENSLAUF, GESUNDHEITSDATEN) |
| `dsgvo_classification.legal_basis` | **Array:** Rechtliche Grundlagen (Art. 9 DSGVO, ¬ß 26 BDSG) |
| `dsgvo_classification.protection_level` | String - Schutzklasse ("hoch", "sehr hoch" oder null) |
| `dsgvo_classification.detected_keywords` | **Objekt:** Gefundene Keywords pro Kategorie |
| `ocr_info` | **Optional:** OCR-Metadaten (nur bei gescannten PDFs) |
| `ocr_info.used_ocr` | Boolean - ob OCR verwendet wurde |
| `ocr_info.ocr_pages` | Anzahl der Seiten, die mit OCR verarbeitet wurden |
| `ocr_info.total_pages` | Gesamtzahl der PDF-Seiten |
| `ocr_info.ocr_chars` | Anzahl der via OCR extrahierten Zeichen |

---

## Funktionsweise

### Verarbeitungspipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Dateiscan mit Live-Fortschrittsanzeige                  ‚îÇ
‚îÇ    ‚îî‚îÄ> Rekursive Durchsuchung des OneDrive-Verzeichnisses  ‚îÇ
‚îÇ    ‚îî‚îÄ> Statistik nach Dateiendungen                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. LM Studio-Verbindungscheck                               ‚îÇ
‚îÇ    ‚îî‚îÄ> Pr√ºfung auf erreichbaren Server                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Dateizugriffspr√ºfung                                     ‚îÇ
‚îÇ    ‚îî‚îÄ> OneDrive-Dateien sind direkt verf√ºgbar auf macOS    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Bildgr√∂√üenfilter (f√ºr PNG/JPG/JPEG)                     ‚îÇ
‚îÇ    ‚îî‚îÄ> √úberspringt Dateien < 10 KB (Icons)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Textextraktion                                           ‚îÇ
‚îÇ    ‚îú‚îÄ> PDF: pdfplumber + OCR-Fallback (Tesseract)         ‚îÇ
‚îÇ    ‚îÇ   ‚îî‚îÄ> Automatische OCR-Erkennung bei <10 Zeichen/Seite‚îÇ
‚îÇ    ‚îÇ   ‚îî‚îÄ> 300 DPI Aufl√∂sung f√ºr optimale Texterkennung    ‚îÇ
‚îÇ    ‚îú‚îÄ> DOCX/DOC: python-docx                               ‚îÇ
‚îÇ    ‚îú‚îÄ> PPTX/PPT: python-pptx                               ‚îÇ
‚îÇ    ‚îú‚îÄ> XLSX/XLS/XLSM/XLTX: openpyxl (Werte, keine Formeln)‚îÇ
‚îÇ    ‚îú‚îÄ> TXT/MD: UTF-8 + Latin-1 Fallback                   ‚îÇ
‚îÇ    ‚îî‚îÄ> PNG/JPG: Base64 + Vision API                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. LLM-Zusammenfassung                                      ‚îÇ
‚îÇ    ‚îú‚îÄ> Dateityp-spezifische Prompts (AUF DEUTSCH)         ‚îÇ
‚îÇ    ‚îú‚îÄ> Adaptive Textk√ºrzung (30k ‚Üí 3k Zeichen)            ‚îÇ
‚îÇ    ‚îú‚îÄ> Context/Token-Overflow Handling mit Retry           ‚îÇ
‚îÇ    ‚îî‚îÄ> Professionelle Fehlerbehandlung mit Benutzerabfrage ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. JSON-Ausgabe                                             ‚îÇ
‚îÇ    ‚îú‚îÄ> Validierung vorhandener Dateien                     ‚îÇ
‚îÇ    ‚îî‚îÄ> Speicherung unter DST_ROOT                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### RAG-optimierte Wissensextraktion

Das System verwendet einen spezialisierten RAG-Ansatz (Retrieval-Augmented Generation) f√ºr maximale Auffindbarkeit:

**Prompt-Struktur:**
- Sachliche, informationsdichte Zusammenfassungen ohne Meta-Kommentare
- Beibehaltung wichtiger Fachbegriffe, Zahlen, Technologien und Personennamen
- Beschreibung von Zweck, Inhalt, Kontext und Besonderheiten
- Strukturierte Darstellung: Was? Wozu? Welche Inhalte? Was ist besonders?
- **Kommagetrennte Schl√ºsselbegriff-Liste** am Ende jeder Zusammenfassung

**Dateityp-spezifische Schwerpunkte:**
- **PDF/DOCX/DOC**: Dokumenteninhalt, Kernaussagen, Personen und ihre Rollen
- **PPTX/PPT**: Pr√§sentationsthemen, Kernbotschaften, Folienstruktur
- **XLSX/XLS/XLSM/XLTX**: Datenarten, Kategorien, Zahlen, Automatisierung
- **TXT/MD**: Textinhalt, Dokumentstruktur, technische Details
- **PNG/JPG/JPEG**: Bildinhalte, sichtbarer Text, Diagramme, Personen

**Vorteile f√ºr semantische Suche:**
- Maximale Informationsdichte (bis zu 1000 Zeichen)
- **Separates Keywords-Array** f√ºr schnelle Kategorisierung und Filterung
- Automatische Extraktion der Schl√ºsselbegriffe aus der LLM-Antwort
- Keine ablenkenden Formatierungen oder F√ºllw√∂rter
- Optimiert f√ºr Vektorsuche und RAG-Systeme
- Keywords erm√∂glichen effiziente Volltextsuche und Indexierung

### Adaptive Context-Verwaltung

Das System berechnet automatisch die optimale Textl√§nge basierend auf `MAX_CONTEXT_TOKENS`:

**Beispiel f√ºr MAX_CONTEXT_TOKENS = 262144 (ministral-3-14b-reasoning):**
```
Versuch 1: 1.044.576 Zeichen (~261.000 Tokens) - Nutzt fast vollen Context
Versuch 2:   699.666 Zeichen (~175.000 Tokens) - 67% des Max-Context
Versuch 3:   490.951 Zeichen (~123.000 Tokens) - 47% des Max-Context
Versuch 4:   344.710 Zeichen  (~86.000 Tokens) - 33% des Max-Context
Versuch 5:   208.915 Zeichen  (~52.000 Tokens) - 20% des Max-Context
Versuch 6:     3.000 Zeichen     (~750 Tokens) - Minimum-Fallback
```

**Beispiel f√ºr MAX_CONTEXT_TOKENS = 8192 (kleinere Modelle):**
```
Versuch 1: 28.768 Zeichen (~7.200 Tokens)
Versuch 2: 19.274 Zeichen (~4.800 Tokens)
Versuch 3: 13.520 Zeichen (~3.400 Tokens)
Versuch 4:  9.493 Zeichen (~2.400 Tokens)
Versuch 5:  5.753 Zeichen (~1.400 Tokens)
Versuch 6:  3.000 Zeichen   (~750 Tokens)
```

**Annahme**: ~4 Zeichen pro Token (konservativ f√ºr deutsche Texte)

**Verbesserte Fehlerkennung**: Das System erkennt Context-Fehler anhand der Keywords "context", "token" oder "length" in der Fehlermeldung.

---

## Fehlerbehandlung

### Professionelle LM Studio-Fehlerbehandlung (NEU in v1.4.0)

Beim ersten LM Studio-Fehler (Netzwerk, Validierung, Typ-Fehler) wird der Benutzer gefragt, wie fortgefahren werden soll:

1. **Abbrechen**: Programm wird sofort beendet
2. **Weiter ohne Fehlerabfragen**: Fehlerhafte Dateien werden stillschweigend √ºbersprungen
3. **Weiter mit Fehlerabfragen**: Bei jedem Fehler erfolgt eine erneute Abfrage

Diese Einstellung gilt f√ºr den gesamten Durchlauf und wird beim n√§chsten Programmstart zur√ºckgesetzt.

### H√§ufige Probleme und L√∂sungen

#### LM Studio Connection Error
```
FEHLER: LM Studio ist nicht erreichbar!
```

**L√∂sung:**
1. Stellen Sie sicher, dass LM Studio l√§uft
2. Pr√ºfen Sie, ob der Server auf Port 1234 aktiv ist
3. Verifizieren Sie die `LMSTUDIO_API_URL` im Skript
4. √úberpr√ºfen Sie, ob ein Modell geladen ist

#### Context/Token Overflow
```
  ‚Üí Context/Token-Fehler (30000 Zeichen), versuche mit weniger...
```

**L√∂sung:**
- Automatisch gel√∂st durch adaptive Textk√ºrzung
- Bei persistierenden Problemen: Kleineres Modell oder gr√∂√üeres Context-Fenster verwenden
- Erw√§gen Sie ein Reasoning-Modell (ministral-3-14b-reasoning)

#### Vision API Error (Bildanalyse)
```
Vision-Analyse fehlgeschlagen: [Error]
```

**L√∂sung:**
- Laden Sie ein multimodales Modell (LLaVA, BakLLaVA)
- Aktualisieren Sie LM Studio auf die neueste Version
- Pr√ºfen Sie, ob das Modell Vision-Funktionen unterst√ºtzt

#### Legacy Office Format Warnings
```
[.doc-Datei - Textextraktion nicht vollst√§ndig m√∂glich...]
```

**Hinweis:**
- .doc, .ppt, .xls Dateien verwenden alte Bin√§rformate
- F√ºr vollst√§ndige Unterst√ºtzung: Konvertierung zu .docx/.pptx/.xlsx empfohlen
- Oder Installation von LibreOffice/antiword f√ºr erweiterte Unterst√ºtzung

---

## Performance-Optimierung

### Empfohlene Einstellungen

| Aspekt | Empfehlung | Begr√ºndung |
|--------|-----------|------------|
| **Modellgr√∂√üe** | 3B-14B Parameter | Balance zwischen Qualit√§t und Geschwindigkeit |
| **GPU-Offloading** | 100% (Apple Silicon) | 10-50x schnellere Verarbeitung |
| **Batch-Gr√∂√üe** | 1 (Standard) | Sequentielle Verarbeitung mit Validierung |
| **Context-L√§nge** | 8192+ Tokens | Vermeidet h√§ufige Textk√ºrzungen |

### Geschwindigkeitsoptimierung

```python
# In summarize_with_lmstudio():
"temperature": 0.3,      # Niedrig = deterministischer, schneller
"max_tokens": 400,       # Limitiert auf ~1000 Zeichen Output
```

**Erwartete Verarbeitungsgeschwindigkeit (Apple M1/M2):**
- Text-Dateien: 1-3 Sekunden pro Datei
- PDF (mit Text): 3-8 Sekunden pro Datei
- PDF (gescannt, OCR): 10-30 Sekunden pro Datei (abh√§ngig von Seitenzahl)
- DOCX/XLSX/PPTX: 3-8 Sekunden pro Datei
- Bilder (Vision): 8-25 Sekunden pro Datei

**macOS-Optimierungen:**
- Native Apple Silicon-Unterst√ºtzung durch LM Studio
- OneDrive-Dateien sind direkt verf√ºgbar (kein Download n√∂tig)
- Effiziente Speicherverwaltung durch Python 3.12+
- Tesseract OCR mit optimierter Performance auf Apple Silicon

---

## Erweiterte Nutzung

### Skript-Parameter anpassen

#### Zusammenfassungsl√§nge √§ndern
```python
# In get_prompt_for_filetype() - Basis-Prompt:
"Maximal 1000 Zeichen"  # Auf gew√ºnschte L√§nge anpassen

# In summarize_with_lmstudio():
"max_tokens": 400,  # Entsprechend anpassen (~2.5 Zeichen pro Token)
```

#### Retry-Strategie modifizieren
```python
# In summarize_with_lmstudio():
retry_lengths = [30000, 20000, 14000, 10000, 6000, 3000]  # Anpassen nach Bedarf
```

#### Bildgr√∂√üe-Filter √§ndern
```python
MIN_IMAGE_SIZE = 20 * 1024  # 20 KB - strengerer Filter
# oder
MIN_IMAGE_SIZE = 5 * 1024   # 5 KB - weniger streng
```

### Integration in andere Workflows

Das JSON-Ausgabeformat erm√∂glicht einfache Integration:

```python
# Beispiel: JSON-Dateien einlesen und durchsuchen
import json
import glob

summaries = []
for json_file in glob.glob(os.path.expanduser("~/LLM/**/*.json"), recursive=True):
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
        summaries.append(data)

# Suche nach Personennamen in der Zusammenfassung
results = [s for s in summaries if "John Doe" in s.get("summary", "")]

# Suche nach Keywords
keyword_results = [s for s in summaries if "Digitale Transformation" in s.get("keywords", [])]

# Suche nach Named Entities (NEU in v1.12.0)
# Alle Dokumente mit einer bestimmten Firma
company_docs = [s for s in summaries
                if "Example Corp" in s.get("entities", {}).get("companies", [])]

# Alle Dokumente mit einer bestimmten Person
person_docs = [s for s in summaries
               if "Jane Smith" in s.get("entities", {}).get("persons", [])]

# Alle Dokumente mit Institutionen
institution_docs = [s for s in summaries
                    if len(s.get("entities", {}).get("institutions", [])) > 0]

# Kombinierte Entity-Suche
multi_entity = [s for s in summaries
                if any(company in s.get("entities", {}).get("companies", [])
                       for company in ["Example Corp", "Sample Inc"])]

# Gruppierung nach Firmen
from collections import Counter
all_companies = []
for s in summaries:
    all_companies.extend(s.get("entities", {}).get("companies", []))
top_companies = Counter(all_companies).most_common(10)

# Gruppierung nach Keywords
all_keywords = []
for s in summaries:
    all_keywords.extend(s.get("keywords", []))
top_keywords = Counter(all_keywords).most_common(10)

# Cross-Referenz: Welche Personen arbeiten mit welchen Firmen?
person_company_map = {}
for s in summaries:
    persons = s.get("entities", {}).get("persons", [])
    companies = s.get("entities", {}).get("companies", [])
    for person in persons:
        if person not in person_company_map:
            person_company_map[person] = set()
        person_company_map[person].update(companies)

# Weitere Verarbeitung...
```

---

## DSGVO-Klassifizierung (NEU in v1.18.0)

### √úbersicht

FileInventory erkennt automatisch **besonders schutzbed√ºrftige personenbezogene Daten** gem√§√ü:
- **Art. 9 DSGVO** - Besondere Kategorien personenbezogener Daten (Gesundheitsdaten)
- **¬ß 26 BDSG** - Besch√§ftigtendaten

### Erkannte Kategorien

Das System klassifiziert folgende Dokumenttypen:

#### Besch√§ftigtendaten (¬ß 26 BDSG)
- **GEHALTSABRECHNUNG**: Lohnabrechnungen, Entgeltabrechnungen
- **LEBENSLAUF**: Bewerbungsunterlagen, CVs
- **ARBEITSVERTRAG**: Arbeitsvertr√§ge, Anstellungsvertr√§ge
- **ZEUGNIS**: Arbeitszeugnisse, Beurteilungen
- **PERSONALAKTE**: Personalakten, Mitarbeiterdaten

#### Gesundheitsdaten (Art. 9 DSGVO)
- **GESUNDHEITSDATEN**: Atteste, AU-Bescheinigungen, medizinische Dokumente

#### Sozialversicherung & Steuern
- **SOZIALVERSICHERUNG**: SV-Nummer, Rentenversicherungsnachweise
- **STEUER**: Lohnsteuerbescheinigungen, Steuer-ID

#### Weitere sensible Daten
- **AUSWEIS**: Personalausweiskopien, Reisep√§sse
- **BANKDATEN**: IBAN, Kontonummern

### Verwendung

#### Automatische Klassifizierung bei neuen Dokumenten

Alle **neu verarbeiteten** Dokumente werden automatisch klassifiziert:

```bash
python3 FileInventory.py
```

W√§hrend der Verarbeitung wird angezeigt:

```
Klassifiziere DSGVO-relevante Inhalte...
  ‚ö†Ô∏è  DSGVO-WARNUNG: Besonders schutzbed√ºrftige Daten erkannt!
      Kategorien: GEHALTSABRECHNUNG
      Schutzklasse: hoch
```

#### Bestehende JSON-Dateien aktualisieren

F√ºr bereits verarbeitete Dokumente k√∂nnen Sie die Klassifizierung nachtragen:

```bash
# Aktiviere virtuelle Umgebung
source .venv/bin/activate

# Aktualisiere alle JSON-Dateien mit DSGVO-Klassifizierung
python3 FileInventory.py --update-dsgvo
```

**Vorteile:**
- ‚ö° **Sehr schnell** - Nur Regex, kein LLM
- üîí **Keine neue LLM-Verarbeitung** n√∂tig
- üìä **Detaillierte Statistik** nach Abschluss

**Beispielausgabe:**

```
================================================================================
DSGVO-UPDATE: KLASSIFIZIERUNG BESONDERS SCHUTZBED√úRFTIGER DATEN
================================================================================
Analysiere Dokumente gem√§√ü Art. 9 DSGVO und ¬ß 26 BDSG
Durchsuche: ~/LLM
================================================================================

Gefunden: 6,283 JSON-Dateien

Fortschritt: 6,283/6,283 (100.0%) - Aktualisiert: 6,283 - Sensible Daten: 127 - Zeit: 45.2s

================================================================================
DSGVO-UPDATE ABGESCHLOSSEN
================================================================================
Gescannte Dateien: 6,283
Aktualisierte Dateien: 6,283
Dateien mit sensiblen Daten: 127

Gefundene Kategorien besonders schutzbed√ºrftiger Daten:
  ‚Ä¢ GEHALTSABRECHNUNG: 45 Dokumente
  ‚Ä¢ LEBENSLAUF: 38 Dokumente
  ‚Ä¢ ARBEITSVERTRAG: 22 Dokumente
  ‚Ä¢ BANKDATEN: 12 Dokumente
  ‚Ä¢ ZEUGNIS: 10 Dokumente

Gesamtzeit: 45.2s
================================================================================
```

### Integration und Suche

#### Suche nach sensiblen Dokumenten

```python
import json
import glob

# Alle JSON-Dateien einlesen
summaries = []
for json_file in glob.glob(os.path.expanduser("~/LLM/**/*.json"), recursive=True):
    with open(json_file, 'r', encoding='utf-8') as f:
        summaries.append(json.load(f))

# Alle Dokumente mit sensiblen Daten finden
sensitive_docs = [s for s in summaries
                  if s.get("dsgvo_classification", {}).get("contains_sensitive_data")]

print(f"Gefunden: {len(sensitive_docs)} Dokumente mit sensiblen Daten")

# Nach Schutzklasse filtern
very_high = [s for s in sensitive_docs
             if s.get("dsgvo_classification", {}).get("protection_level") == "sehr hoch"]

# Nach Kategorien filtern
gehaltsabrechnungen = [s for s in sensitive_docs
                       if "GEHALTSABRECHNUNG" in s.get("dsgvo_classification", {}).get("data_categories", [])]

# Statistik erstellen
from collections import Counter
categories = []
for s in sensitive_docs:
    categories.extend(s.get("dsgvo_classification", {}).get("data_categories", []))
category_stats = Counter(categories).most_common()

print("\nKategorien:")
for category, count in category_stats:
    print(f"  {category}: {count} Dokumente")
```

### Datenschutz-Hinweise

**Wichtig:**
- Die DSGVO-Klassifizierung erfolgt **ausschlie√ülich keyword-basiert** (Regex)
- **Kein LLM-Zugriff** auf den Dokumentinhalt bei `--update-dsgvo`
- Originaldokumente bleiben **unver√§ndert**
- Klassifizierung dient der **besseren Auffindbarkeit** sensibler Daten
- Hilft bei **Compliance-Pr√ºfungen** und **Datenaudits**

**Empfehlung:**
- Regelm√§√üige √úberpr√ºfung der als "sensibel" klassifizierten Dokumente
- Angemessene Zugriffskontrollen f√ºr Dokumente mit hoher Schutzklasse
- Dokumentation der Verarbeitungszwecke gem√§√ü DSGVO Art. 30

---

## Sicherheit und Datenschutz

### Lokale Verarbeitung
- **Alle Daten bleiben lokal**: Keine Cloud-API-Aufrufe
- **OneDrive-Dateien**: Lokal synchronisiert und verarbeitet
- **LLM-Inferenz**: Vollst√§ndig offline √ºber LM Studio
- **DSGVO-Klassifizierung**: Regex-basiert, kein LLM-Zugriff (bei `--update-dsgvo`)

### Datensicherheit
- JSON-Ausgaben enthalten nur Metadaten und Zusammenfassungen
- Originaldateien bleiben unver√§ndert
- Keine √úbertragung sensibler Informationen
- Keine Telemetrie oder Analytics
- DSGVO-konforme Verarbeitung personenbezogener Daten

---

## Versionsverlauf

### Version 1.18.0 (2025-12-30)
- **Neu**: DSGVO-Klassifizierung f√ºr besonders schutzbed√ºrftige personenbezogene Daten
- **Neu**: Automatische Erkennung gem√§√ü Art. 9 DSGVO (Gesundheitsdaten) und ¬ß 26 BDSG (Besch√§ftigtendaten)
- **Neu**: 10 Kategorien: Gehaltsabrechnungen, Lebensl√§ufe, Arbeitsvertr√§ge, Zeugnisse, Personalakten, Gesundheitsdaten, Sozialversicherung, Steuerdaten, Ausweise, Bankdaten
- **Neu**: `classify_sensitive_data()` Funktion mit Keyword-basierter Erkennung (Regex)
- **Neu**: `dsgvo_classification` Objekt in JSON-Ausgabe mit Kategorien, Rechtsgrundlagen und Schutzklassen
- **Neu**: `--update-dsgvo` Parameter zum Aktualisieren bestehender JSON-Dateien (sehr schnell, kein LLM)
- **Neu**: `update_json_with_dsgvo_classification()` Funktion f√ºr inkrementelles Update
- **Neu**: `update_all_jsons_with_dsgvo()` Batch-Verarbeitung aller JSON-Dateien
- **Neu**: Schutzklassen ("hoch" / "sehr hoch") basierend auf Datenkategorie
- **Neu**: Detaillierte Statistiken mit gefundenen Kategorien und Dokumentenanzahl
- **Verbessert**: Warnungen w√§hrend der Verarbeitung bei Erkennung sensibler Daten
- **Dokumentiert**: Umfangreicher README-Abschnitt mit Beispielen und Datenschutzhinweisen
- **Compliance**: Hilft bei DSGVO-Audits und Datenklassifizierung

### Version 1.12.0 (2025-12-28)
- **Neu**: Named Entity Recognition (NER) - Automatische Extraktion von Firmen, Personen, Institutionen und Organisationen
- **Neu**: `extract_entities_with_lmstudio()` Funktion f√ºr strukturierte Entity-Extraktion
- **Neu**: `extract_entities_from_image()` f√ºr Vision-basierte Entity-Extraktion aus Bildern
- **Neu**: `parse_entity_response()` mit robustem Parsing f√ºr mehrsprachige Labels
- **Neu**: `entities` Objekt in JSON-Ausgabe mit vier Kategorien (companies, persons, institutions, organizations)
- **Neu**: Entity-Extraktion funktioniert auch bei kurzen Texten (< 1500 Zeichen) die nicht zusammengefasst werden
- **Neu**: Intelligente Textk√ºrzung f√ºr sehr lange Dokumente (erste 6000 + letzte 2000 Zeichen)
- **Verbessert**: Niedrige Temperatur (0.1) f√ºr konsistente Entity-Extraktion
- **Verbessert**: Fortschrittsanzeige zeigt Anzahl gefundener Entities pro Kategorie
- **Verbessert**: Duplikat-Entfernung in Entity-Listen
- **Dokumentiert**: Erweiterte README mit Entity-Feldern und Beispielen
- **Kompatibilit√§t**: Funktioniert mit Text- und Vision-Modellen

### Version 1.11.0 (2025-12-28)
- **Neu**: Intelligente Lernlogik f√ºr erfolgreiche Context-Gr√∂√üen
- **Neu**: Globaler `_LEARNED_MAX_CHARS` Cache zur Optimierung zuk√ºnftiger Versuche
- **Verbessert**: Adaptive Retry-Strategie mit 9 Schritten statt 6 (100%, 85%, 70%, 55%, 40%, 30%, 20%, 15%)
- **Verbessert**: Startet bei 90% der gelernten erfolgreichen Gr√∂√üe f√ºr weniger Fehlversuche
- **Verbessert**: Sanftere √úberg√§nge zwischen Retry-Versuchen
- **Fix**: Vermeidet Sprung von 20.878 ‚Üí 3.000 Zeichen durch prozentuale Reduktion
- **Optimiert**: Weniger LLM-Aufrufe durch Learning-Mechanismus

### Version 1.10.0 (2025-12-28)
- **Neu**: `--summary-max-chars` Parameter zur Steuerung der Zusammenfassungsl√§nge
- **Neu**: Automatisches √úberspringen von LLM f√ºr Texte ‚â§ SUMMARY_MAX_CHARS (direkte Kopie statt Zusammenfassung)
- **Verbessert**: SUMMARY_MAX_CHARS auf 1500 Zeichen erh√∂ht
- **Verbessert**: Dynamische max_tokens Berechnung: `int(summary_max_chars / 2.5) + 50`
- **Verbessert**: `get_prompt_for_filetype()` akzeptiert nun `summary_max_chars` Parameter
- **Optimiert**: Spart LLM-Aufrufe und Zeit bei kurzen Dokumenten
- **Dokumentiert**: Neue Parameter in README mit Beispielen

### Version 1.9.0 (2025-12-28)
- **Neu**: `--create-database` Parameter zum Erstellen kombinierter JSON-Datenbanken
- **Neu**: Automatische Aufteilung in mehrere Dateien basierend auf Gr√∂√üenlimit
- **Neu**: `--database-output DIR` zur Angabe eines benutzerdefinierten Ausgabeverzeichnisses
- **Neu**: `--max-database-size MB` zur Kontrolle der maximalen Datenbankdateigr√∂√üe
- **Neu**: Metadaten in Datenbank-Dateien (Version, Zeitstempel, Quellverzeichnisse)
- **Neu**: Fortschrittsanzeige w√§hrend der Datenbank-Erstellung
- **Neu**: Detaillierte Statistiken nach Datenbank-Erstellung
- **Verbessert**: Optimiert f√ºr ChatGPT/Claude-Integration
- **Verbessert**: JSON-Struktur mit separaten Metadaten und Dokumenten-Arrays
- **Dokumentiert**: Neue Sektion in README mit Beispielen und Best Practices

### Version 1.8.0 (2025-12-25)
- **Neu**: Alphabetische Sortierung von Verzeichnissen und Dateien w√§hrend der Verarbeitung
- **Neu**: Zeitstempelpr√ºfung beim √úberspringen existierender JSON-Dateien
- **Verbessert**: Automatische Neuverarbeitung wenn `created` oder `modified` Zeitstempel ge√§ndert wurden
- **Verbessert**: Konsistente Verarbeitungsreihenfolge durch Sortierung
- **Fix**: Verhindert √ºbersprungene Updates bei Datei√§nderungen

### Version 1.7.4 (2025-12-25)
- **Debug**: Erweiterte Fehlerausgaben bei Context/Token-Fehlern
- **Debug**: Zeigt gesch√§tzte Token-Anzahl und tats√§chliche LLM-Fehlermeldung
- **Verbessert**: Bessere Diagnose von Context-Problemen f√ºr Fehlersuche
- **Hilfe**: Erm√∂glicht Identifikation von LM Studio Konfigurationsproblemen

### Version 1.7.3 (2025-12-25)
- **Verbessert**: Breitere erste Spalte in Dateiendungen-Statistik (18 statt 10 Zeichen)
- **Fix**: Lange Dateiendungen wie ".herunterladen" werden jetzt korrekt dargestellt
- **Optimiert**: Tabellenbreite auf 80 Zeichen erweitert f√ºr bessere Lesbarkeit

### Version 1.7.2 (2025-12-25)
- **Fix**: Intelligente retry_lengths - ber√ºcksichtigt jetzt tats√§chliche Textl√§nge
- **Optimiert**: Vermeidet unn√∂tige Retry-Versuche mit zu gro√üen Textl√§ngen
- **Verbessert**: Entfernt Duplikate aus retry_lengths f√ºr effizientere Verarbeitung
- **Beispiel**: 23k Zeichen Text ‚Üí nur 2 Versuche statt 6

### Version 1.7.1 (2025-12-25)
- **Neu**: `--max-tokens TOKENS` Parameter f√ºr dynamische Context-L√§nge
- **Verbessert**: MAX_CONTEXT_TOKENS kann per Kommandozeile √ºberschrieben werden
- **Verbessert**: Erweiterte Hilfe mit Beispielen f√ºr verschiedene Modellgr√∂√üen
- **Optimiert**: Flexible Anpassung an verschiedene LLM-Modelle ohne Code-√Ñnderung

### Version 1.7.0 (2025-12-25)
- **Neu**: Professionelle Kommandozeilenparameter-Unterst√ºtzung mit argparse
- **Neu**: `-h` / `--help` zeigt Hilfe und alle verf√ºgbaren Optionen
- **Neu**: `--version` zeigt Versionsinformation an
- **Neu**: `--src VERZEICHNIS` f√ºr benutzerdefiniertes Quellverzeichnis
- **Neu**: `--dst VERZEICHNIS` f√ºr benutzerdefiniertes Zielverzeichnis
- **Verbessert**: Detaillierte Hilfe mit Beispielen und Konfigurationshinweisen
- **Dokumentiert**: Alle Parameter in der README mit Beispielen

### Version 1.6.8 (2025-12-25)
- **Neu**: Konfigurierbare MAX_CONTEXT_TOKENS f√ºr unterschiedliche Modellgr√∂√üen
- **Neu**: Automatische Berechnung der retry_lengths basierend auf Modell-Context
- **Verbessert**: Unterst√ºtzung f√ºr gro√üe Context-Fenster (bis 262k Tokens)
- **Getestet**: Erfolgreich mit mistralai/ministral-3-14b-reasoning (262k Tokens)
- **Optimiert**: Bessere Nutzung der verf√ºgbaren Context-L√§nge

### Version 1.6.7 (2025-12-25)
- **Neu**: OCR-Funktionalit√§tspr√ºfung beim Programmstart mit detailliertem Status
- **Neu**: Pr√ºfung ob Tesseract installiert ist und deutsche Sprache verf√ºgbar ist
- **Fix**: OCR_AVAILABLE als globale Variable - behebt "name 'ocr_available' is not defined" Fehler
- **Verbessert**: Klare Warnung beim Start wenn OCR nicht verf√ºgbar ist
- **Verbessert**: Anzeige der Tesseract-Version und Sprachunterst√ºtzung

### Version 1.6.6 (2025-12-25)
- **Verbessert**: Deutlich verbesserte Fehlermeldung f√ºr gescannte PDFs ohne OCR-Unterst√ºtzung
- **Verbessert**: Zeigt Installationsanweisungen f√ºr Tesseract OCR an (macOS, Linux, Python)
- **Verbessert**: Klar abgegrenzte Warnung mit Erkl√§rung warum Datei √ºbersprungen wird
- **Fix**: Benutzer werden jetzt direkt informiert dass OCR-Installation ben√∂tigt wird

### Version 1.6.5 (2025-12-25)
- **Fix**: Keyword-Extraktion funktioniert jetzt korrekt mit "Schl√ºsselbegriffe:", "Keywords:" Markern
- **Verbessert**: Robuste Regex-basierte Keyword-Erkennung mit mehreren Fallback-Optionen
- **Verbessert**: Keywords werden auch bei l√§ngeren Zeilen (>200 Zeichen) korrekt extrahiert
- **Verbessert**: Automatisches Entfernen der Keyword-Zeile aus der Zusammenfassung

### Version 1.6.4 (2025-12-25)
- **Fix**: OCR-Z√§hler funktioniert jetzt auch bei √ºbersprungenen (bereits verarbeiteten) Dateien
- **Verbessert**: Prompts optimiert - kein Markdown, keine Meta-Begriffe wie "Zusammenfassung" oder "Diese Datei enth√§lt"
- **Verbessert**: System-Prompt fordert reinen Flie√ütext ohne Formatierung
- **Verbessert**: Direkter Einstieg in Inhalte ohne Einleitungen

### Version 1.6.3 (2025-12-25)
- **Fix**: OCR-Z√§hler wird jetzt korrekt aktualisiert (auch bei bereits verarbeiteten Dateien)
- **Fix**: OCR-Warnung "nicht verf√ºgbar" erscheint nur einmal pro PDF statt bei jeder Seite
- **Verbessert**: OCR-Import-Check erfolgt einmal zu Beginn der PDF-Verarbeitung
- **Verbessert**: OCR-Statistik aus existierenden JSON-Dateien wird korrekt gelesen

### Version 1.6.2 (2025-12-25)
- **Optimiert**: Redundantes `name` Feld aus JSON-Struktur entfernt
- **Verbessert**: Dateiname ist bereits im `path` Feld enthalten
- **Optimiert**: Schlankere JSON-Dateien durch reduzierten Speicherbedarf

### Version 1.6.1 (2025-12-25)
- **Neu**: Separates `keywords` Feld in JSON-Struktur
- **Neu**: Automatische Extraktion der Schl√ºsselbegriffe aus LLM-Antwort
- **Verbessert**: Keywords als Array f√ºr einfache Filterung und Suche
- **Verbessert**: Zusammenfassung und Keywords werden getrennt gespeichert
- **Optimiert**: README mit erweiterten Integration-Beispielen

### Version 1.6.0 (2025-12-25)
- **Neu**: RAG-optimierte Prompt-Struktur f√ºr semantische Suche
- **Neu**: Kommagetrennte Schl√ºsselbegriff-Liste in jeder Zusammenfassung
- **Verbessert**: Zusammenfassungsl√§nge auf 1000 Zeichen erh√∂ht
- **Verbessert**: Informationsdichte durch strukturierte Wissensextraktion
- **Verbessert**: System-Prompt fokussiert auf Fakten, Zahlen und Fachbegriffe
- **Verbessert**: max_tokens auf 400 erh√∂ht f√ºr l√§ngere Ausgaben
- **Optimiert**: Prompts ohne Meta-Kommentare und F√ºllw√∂rter
- **Optimiert**: Bessere Auffindbarkeit durch strukturierte Darstellung (Was? Wozu? Welche Inhalte? Besonderheiten?)

### Version 1.5.1 (2025-12-25)
- **Neu**: OCR-Statistiken und -Berichterstattung
- **Neu**: OCR-Dokumentenz√§hler in Fortschrittsberichten
- **Neu**: Detaillierte OCR-Informationen in JSON-Ausgabe
- **Neu**: OCR-Z√§hler im Abschlussbericht
- **Verbessert**: Besseres Error-Handling mit Traceback bei Fehlern
- **Fix**: Robuste Tuple-Unpacking-Logik f√ºr extract_text()

### Version 1.5.0 (2025-12-25)
- **Neu**: OCR-Unterst√ºtzung f√ºr gescannte PDFs mit Tesseract
- **Neu**: Automatische Erkennung von Scan-PDFs (<10 Zeichen pro Seite)
- **Neu**: 300 DPI Aufl√∂sung f√ºr optimale OCR-Qualit√§t
- **Neu**: Fortschrittsanzeige f√ºr mehrseitige OCR-Verarbeitung
- **Neu**: Deutsche Sprachunterst√ºtzung f√ºr OCR (lang='deu')
- **Neu**: OCR-Metadaten in R√ºckgabewerten (used_ocr, ocr_pages, total_pages, ocr_chars)
- **Verbessert**: Detaillierte OCR-Ergebnisausgabe

### Version 1.4.2 (2025-12-25)
- **Neu**: Erzwinge deutsche Sprache in allen LLM-Zusammenfassungen ("AUF DEUTSCH")
- **Neu**: Zeige nur erste 100 Zeichen der Zusammenfassung
- **Verbessert**: Berechne Durchschnittszeit nur f√ºr verarbeitete Dateien (nicht √ºbersprungene)

### Version 1.4.1 (2025-12-25)
- **Fix**: Akzeptiere J/N Eingaben in Gro√ü- und Kleinschreibung
- **Fix**: Fehlende Zusammenfassungs-Ausgabe wiederhergestellt

### Version 1.4.0 (2025-12-25)
- **Neu**: Professionelle Fehlerbehandlung mit interaktiven Benutzerabfragen
- **Neu**: Fehlerbehandlungsmodus (Abbrechen/Weiter ohne Fragen/Weiter mit Fragen)
- **Neu**: Globaler ERROR_HANDLING_MODE f√ºr konsistentes Verhalten
- **Verbessert**: ask_on_lmstudio_error() mit professionellem Layout
- **Verbessert**: Detaillierte Fehlerberichterstattung

### Version 1.3.9 (2025-12-25)
- **Verbessert**: Robuste Token/Context-Fehlerkennung
- **Fix**: Erkennung von "token", "context", "length" in Fehlermeldungen
- **Fix**: HTTP 400 Fallback auch bei JSON-Parse-Fehlern

### Version 1.3.8 (2025-12-25)
- **Neu**: LM Studio Connection Check vor Verarbeitung
- **Neu**: Minimale Bildgr√∂√üe (10 KB) - ignoriert Icons
- **Verbessert**: Fehlermeldungen bei nicht erreichbarem LM Studio

### Version 1.3.7 (2025-12-25)
- **Neu**: Unterst√ºtzung f√ºr .doc, .ppt, .xls, .xlsm, .xltx
- **Neu**: Dateityp-spezifische Extraktionsfunktionen
- **Verbessert**: Fallback-Mechanismen f√ºr alte Office-Formate

### Version 1.3.6 (2025-12-25)
- **Neu**: Dateiendungs-Statistik nach Verzeichnisscan
- **Neu**: Markierung welche Dateitypen analysiert werden
- **Verbessert**: √úbersichtlichere Darstellung mit Anzahl, Gr√∂√üe, Durchschnitt

### Version 1.3.5 (2025-12-25)
- **Fix**: Fortschrittsbalken √ºberschreibt nun korrekt l√§ngere Zeilen
- **Verbessert**: last_line_length tracking f√ºr saubere Terminal-Ausgabe

### Version 1.3.0 (2025-12-25)
- **macOS-Portierung**: Vollst√§ndige Anpassung f√ºr macOS
- **Neu**: select() statt msvcrt f√ºr Tastatureingabe
- **Entfernt**: Windows-spezifische OneDrive Download-Logik
- **Neu**: Fortschrittsbalken beim Verzeichnisscan
- **Verbessert**: Terminal-Ausgabe mit \r f√ºr √ºberschreibende Updates

### Version 1.2.0 (2025-12-23)
- **Neu**: Adaptive Textk√ºrzung mit 6 Retry-Stufen
- **Neu**: Verbesserte Context-Overflow-Erkennung
- **Verbessert**: Reasoning-Model-Kompatibilit√§t

### Version 1.1.0 (2025-12-22)
- **Neu**: Unterst√ºtzung f√ºr TXT, MD, PNG, JPG/JPEG
- **Neu**: Dateityp-spezifische Prompts f√ºr bessere Zusammenfassungen
- **Neu**: Vision API-Integration f√ºr Bildanalyse
- **Verbessert**: Text-Encoding mit UTF-8/Latin-1 Fallback

### Version 1.0.0 (2025-12-22)
- Initiale Version (Windows)
- Unterst√ºtzung f√ºr PDF, DOCX, PPTX, XLSX
- OneDrive-Integration
- Adaptive Context-Verwaltung
- JSON-Validierung
- Pause/Resume-Funktionalit√§t

---

## Support und Feedback

### Technischer Support
Bei Problemen oder Fragen:

1. √úberpr√ºfen Sie die [Fehlerbehandlung](#fehlerbehandlung)
2. Validieren Sie Ihre [Konfiguration](#konfiguration)
3. Pr√ºfen Sie die LM Studio Logs
4. √úberpr√ºfen Sie Terminal-Ausgaben auf Hinweise
5. Kontaktieren Sie den Entwickler mit detaillierten Fehlerprotokollen

### Feature-Requests
Vorschl√§ge f√ºr neue Funktionen sind willkommen. Bitte spezifizieren Sie:
- Gew√ºnschte Funktionalit√§t
- Anwendungsfall
- Priorit√§t
- Plattform (macOS/Windows)

---

## Lizenz und Urheberrecht

**Copyright ¬© 2025 - Alle Rechte vorbehalten**

Dieses Tool ist propriet√§re Software f√ºr den internen Gebrauch. Vervielf√§ltigung, Weitergabe oder kommerzielle Nutzung ohne ausdr√ºckliche Genehmigung ist untersagt.

---

## Technische Spezifikationen

### Architektur
- **Sprache**: Python 3.8+ (optimiert f√ºr 3.12+)
- **Paradigma**: Prozedural mit funktionaler Extraktion
- **Threading**: Single-threaded (sequentielle Verarbeitung)
- **Encoding**: UTF-8 (Standard), Latin-1 (Fallback)
- **Plattform**: macOS (native Unterst√ºtzung)

### API-Kompatibilit√§t
- **LM Studio**: OpenAI-kompatibles Chat Completion API
- **HTTP-Protokoll**: POST-Requests mit JSON-Payload
- **Timeout**: 300 Sekunden (5 Minuten) pro Request
- **Vision API**: Base64-kodierte Bilder mit multimodalen Modellen

### Ressourcenverbrauch (macOS)
- **RAM**: ~200-500 MB (Skript) + LLM-Modell (3-14 GB)
- **CPU**: Niedrig (Hauptlast auf Apple Neural Engine/GPU f√ºr LLM)
- **Netzwerk**: Nur f√ºr OneDrive-Synchronisation
- **Festplatte**: ~1-5 KB pro JSON-Ausgabe

### macOS-spezifische Features
- **Non-blocking Input**: select.select() f√ºr Tastatureingabe
- **Path Expansion**: os.path.expanduser() f√ºr ~ Pfade
- **OneDrive**: Direkte Verarbeitung synchronisierter Dateien
- **Terminal**: ANSI-kompatible Fortschrittsanzeige

---

**Entwickelt mit Pr√§zision f√ºr effiziente Dokumentenanalyse auf macOS**
